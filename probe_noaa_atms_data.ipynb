{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa26a151",
   "metadata": {},
   "source": [
    "#  Decipher NOAA JPSS Files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec495bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "sdr_files = sorted( [ f for f in os.listdir(\".\") if f[:5] in [ \"GATMO\", \"SATMS\" ] and f[-3:]==\".h5\" ] )\n",
    "other_files = sorted( [ f for f in os.listdir(\".\") if f[:5] not in [ \"GATMO\", \"SATMS\" ] and f[-3:]==\".h5\" ] )\n",
    "print( \"\\n\".join( sdr_files + other_files ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5730170",
   "metadata": {},
   "source": [
    "## h5py\n",
    "\n",
    "Try to make sense of files using Python package h5py. First, define a recursive function that can \n",
    "list datasets in an HDF5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999179b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printkeys( obj, prefix=None ): \n",
    "    if prefix is None: \n",
    "        p = []\n",
    "        try: \n",
    "            keys = set( obj.keys() )\n",
    "        except: \n",
    "            return\n",
    "    else: \n",
    "        p = [ prefix ]\n",
    "        print( prefix )\n",
    "        try: \n",
    "            keys = set( obj[prefix].keys() )\n",
    "        except: \n",
    "            return\n",
    "        \n",
    "    for key in keys: \n",
    "        printkeys( obj, prefix=\"/\".join( p + [key] ) )\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497457a6",
   "metadata": {},
   "source": [
    "Open an HDF5 file and generate a list of its datasets/objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2751d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "for file in sdr_files: \n",
    "    print( f\"\\n==========\\nfile = {file}\" )\n",
    "    d = h5py.File( file, 'r' )\n",
    "    printkeys( d )\n",
    "    d.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df4f63",
   "metadata": {},
   "source": [
    "Probe for brightness temperature data, geolocation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e87f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "d = h5py.File( \"SATMS_j02_d20250410_t0000298_e0001014_b12509_c20250410004550539000_oeac_ops.h5\", 'r' )\n",
    "e = d['All_Data/ATMS-SDR_All/BrightnessTemperature']\n",
    "print( e.attrs.keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d762f",
   "metadata": {},
   "source": [
    "## satpy\n",
    "\n",
    "Experiment with satpy for same files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import satpy\n",
    "d = satpy.Scene( sdr_files, reader=\"atms_sdr_hdf5\" )\n",
    "\n",
    "if True: \n",
    "    print( \"\\nhelp( d ) = \" )\n",
    "    help( d )\n",
    "if True: \n",
    "    print( \"\\navailable_dataset_names = \" )\n",
    "    print( d.available_dataset_names() )\n",
    "if True: \n",
    "    print( \"\\navailable_dataset_ids = \" )\n",
    "    print( d.available_dataset_ids() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.load( [ str(i+1) for i in range(22) ] )\n",
    "e = d.to_xarray_dataset()\n",
    "# print( e )\n",
    "# print( e.coords.keys() )\n",
    "# print( e.data_vars.keys() )\n",
    "print( e.data_vars['1'][:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2258d2",
   "metadata": {},
   "source": [
    "## NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file = \"SFR_v2r0_n21_s202504100000298_e202504100001014_c202504100046490.nc\"\n",
    "d = Dataset( file, 'r' )\n",
    "\n",
    "print( d )\n",
    "print()\n",
    "print( d.variables )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88668f11",
   "metadata": {},
   "source": [
    "## Pan's code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import convert_satms_hdf5torad as pan\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "\n",
    "inputfile = [ f for f in sdr_files if f[:5] == \"SATMS\" ][0]\n",
    "inputfile_geo = [ f for f in sdr_files if f[:5] == \"GATMO\" ][0]\n",
    "outputfile = \"out_atms_sdr.nc\"\n",
    "\n",
    "sdr = pan.sdrReader( inputfile, inputfile_geo )\n",
    "rad = pan.sdr2rad( sdr )\n",
    "pan.radWriter( outputfile, rad )\n",
    "\n",
    "d = Dataset( outputfile, 'r' )\n",
    "print( d )\n",
    "print( \"\\n\\nVariables\\n=========\\n\")\n",
    "for name, var in d.variables.items(): \n",
    "    print( var )\n",
    "    print( )\n",
    "\n",
    "print( d.variables['date'][:20] )\n",
    "\n",
    "d.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d8c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
